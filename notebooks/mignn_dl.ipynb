{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "28160db0-36b9-4675-906b-f69716765853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mitsuba as mi\n",
    "import os\n",
    "mi.set_variant(\"scalar_rgb\")\n",
    "\n",
    "# Create an alias for convenience\n",
    "from mitsuba import ScalarTransform4f as T\n",
    "\n",
    "def load_sensor(r, phi, theta, target):\n",
    "    # Apply two rotations to convert from spherical coordinates to world 3D coordinates.\n",
    "    origin = T.rotate([0, 0, 1], phi).rotate([0, 1, 0], theta) @ mi.ScalarPoint3f([0, 0, r])\n",
    "\n",
    "    return mi.load_dict({\n",
    "        'type': 'perspective',\n",
    "        'fov': 25,\n",
    "        # -1 0 0 0 0 1 0 1 0 0 -1 6.8 0 0 0 1\n",
    "        'to_world': T.look_at(\n",
    "            origin=origin,\n",
    "            target=target,\n",
    "            up=[0, 1, 0]\n",
    "        ),\n",
    "        'sampler': {\n",
    "            'type': 'independent',\n",
    "            'sample_count': 10\n",
    "        },\n",
    "        'film': {\n",
    "            'type': 'hdrfilm',\n",
    "            'width': 64,\n",
    "            'height': 64,\n",
    "            'rfilter': {\n",
    "                'type': 'tent',\n",
    "            },\n",
    "            'pixel_format': 'rgb',\n",
    "        },\n",
    "    })\n",
    "\n",
    "sensor_count = 6\n",
    "\n",
    "radius = 5\n",
    "phis = [ 140 - (i*20) for i in range(sensor_count)]\n",
    "theta = 22\n",
    "\n",
    "sensors = [load_sensor(radius, phi, theta, [0, 1, 0]) for phi in phis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "83e87823-5c79-44d6-9891-0febca1db4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(scene_file, max_depth, data_spp, ref_spp, sensors, output_folder):\n",
    "        \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    scene = mi.load_file(scene_file)\n",
    "\n",
    "    ref_integrator = mi.load_dict({'type': 'path', 'max_depth': max_depth})\n",
    "    gnn_integrator = mi.load_dict({'type': 'pathgnn', 'max_depth': max_depth})\n",
    "        \n",
    "    # generate gnn file data and references\n",
    "    ref_images = []\n",
    "    output_gnn_files = []\n",
    "    \n",
    "    print(f'Generation of {len(sensors)} views for `{scene_file}`')\n",
    "    for view_i, sensor in enumerate(sensors):\n",
    "        \n",
    "        print(f'Generating data for view n°{view_i+1}')\n",
    "        ref_images.append(mi.render(scene, spp=ref_spp, integrator=ref_integrator, sensor=sensor))\n",
    "        \n",
    "        print(f' -- reference of view n°{view_i+1} generated...')\n",
    "        params = mi.traverse(scene)\n",
    "        gnn_log_filename = f'{output_folder}/gnn_file_{view_i}.path'\n",
    "        params['logfile'] = gnn_log_filename\n",
    "        params.update();\n",
    "        \n",
    "        if not os.path.exists(gnn_log_filename):\n",
    "            mi.render(scene, spp=data_spp, integrator=gnn_integrator, sensor=sensor)\n",
    "        print(f' -- GNN data of view n°{view_i+1} generated...')\n",
    "        \n",
    "        output_gnn_files.append(gnn_log_filename)\n",
    "        \n",
    "    return output_gnn_files, ref_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "228bcd67-a787-45cb-bef8-0bdd0081ca12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of 6 views for `scenes/cornell-box/scene.xml`\n",
      "Generating data for view n°1\n",
      " -- reference of view n°1 generated...\n",
      " -- GNN data of view n°1 generated...\n",
      "Generating data for view n°2\n",
      " -- reference of view n°2 generated...\n",
      " -- GNN data of view n°2 generated...\n",
      "Generating data for view n°3\n",
      " -- reference of view n°3 generated...\n",
      " -- GNN data of view n°3 generated...\n",
      "Generating data for view n°4\n",
      " -- reference of view n°4 generated...\n",
      " -- GNN data of view n°4 generated...\n",
      "Generating data for view n°5\n",
      " -- reference of view n°5 generated...\n",
      " -- GNN data of view n°5 generated...\n",
      "Generating data for view n°6\n",
      " -- reference of view n°6 generated...\n",
      " -- GNN data of view n°6 generated...\n"
     ]
    }
   ],
   "source": [
    "scene_file = 'scenes/cornell-box/scene.xml'\n",
    "gnn_files, ref_images = prepare_data(scene_file, \n",
    "                                max_depth = 5, \n",
    "                                data_spp = 10, \n",
    "                                ref_spp = 1000, \n",
    "                                sensors = sensors, \n",
    "                                output_folder = 'data/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3a27f146-f317-442a-a616-34f9ababf1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load of `data/model1/gnn_file_0.path` in progress: 100.00%\n",
      "Load of `data/model1/gnn_file_1.path` in progress: 100.00%\n",
      "Load of `data/model1/gnn_file_2.path` in progress: 100.00%\n",
      "Load of `data/model1/gnn_file_3.path` in progress: 100.00%\n",
      "Load of `data/model1/gnn_file_4.path` in progress: 100.00%\n",
      "Load of `data/model1/gnn_file_5.path` in progress: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from mignn.container import SimpleLightGraphContainer\n",
    "\n",
    "containers = []\n",
    "for gnn_i, gnn_file in enumerate(gnn_files):\n",
    "    ref_image = ref_images[gnn_i]\n",
    "    container = SimpleLightGraphContainer.fromfile(gnn_file, scene_file, ref_image, verbose=True)\n",
    "    containers.append(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "b5b0dbee-1edc-4566-98f6-51b55cd9f952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connections build 0.15%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerome/Documents/Research/Development/Rendering/mitsuba3/build-gnn/python/drjit/router.py:1753: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1.0 / arg\n",
      "/home/jerome/Documents/Research/Development/Rendering/mitsuba3/build-gnn/python/drjit/generic.py:194: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  ar[i] = a0[i] * a1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connections build 37.01%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[230], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# build connections individually\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m container \u001b[38;5;129;01min\u001b[39;00m containers:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes_per_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m merged_graph_container \u001b[38;5;241m=\u001b[39m LightGraphManager\u001b[38;5;241m.\u001b[39mfusion(containers)\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/mignn/container/base.py:69\u001b[0m, in \u001b[0;36mGraphContainer.build_connections\u001b[0;34m(self, n_graphs, n_nodes_per_graphs, n_neighbors, verbose)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_connections\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_graphs: \u001b[38;5;28mint\u001b[39m, n_nodes_per_graphs: \u001b[38;5;28mint\u001b[39m, n_neighbors: \u001b[38;5;28mint\u001b[39m, \\\n\u001b[1;32m     65\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (key, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[0;32m---> 69\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_pos_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes_per_graphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConnections build \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100.\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     73\u001b[0m                 end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/mignn/container/simple.py:31\u001b[0m, in \u001b[0;36mSimpleLightGraphContainer._build_pos_connections\u001b[0;34m(self, pos, n_graphs, n_nodes_per_graphs, n_neighbors)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# use of mitsuba in order to build new connections\u001b[39;00m\n\u001b[1;32m     30\u001b[0m mi\u001b[38;5;241m.\u001b[39mset_variant(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mi_variant)\n\u001b[0;32m---> 31\u001b[0m scene \u001b[38;5;241m=\u001b[39m \u001b[43mmi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_scene_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(pos)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graphs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mignn.manager import LightGraphManager\n",
    "\n",
    "# build connections individually\n",
    "for container in containers:\n",
    "    container.build_connections(n_graphs=10, n_nodes_per_graphs=5, n_neighbors=5, verbose=True)\n",
    "    \n",
    "merged_graph_container = LightGraphManager.fusion(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42b211-e4ab-4691-a68c-4bb007011b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(merged_graph_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0c52b-e338-47a3-89e5-e4b45a9387e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def embedded_data(x_node, L=6):\n",
    "    \"\"\"\n",
    "    Gets a base embedding for one dimension with sin and cos intertwined\n",
    "    \"\"\"\n",
    "    n_elements = x_node.shape[0]\n",
    "    powers = torch.pow(2., torch.arange(L))\n",
    "    \n",
    "    emb_data = []\n",
    "    \n",
    "    for p in x_node:\n",
    "        coord_data = torch.empty(0)\n",
    "        for coord in p:\n",
    "            x_cos = torch.cos(coord * powers)\n",
    "            x_sin = torch.cos(coord * powers)\n",
    "            coord_emb = torch.cat((coord.unsqueeze(0), x_cos, x_sin), 0)\n",
    "            coord_data = torch.cat((coord_data, coord_emb), 0)\n",
    "        emb_data.append(coord_data)\n",
    "    \n",
    "    return torch.stack(emb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863614f3-2d1e-43c6-aab4-83c0e79c5942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for key in merged_graph_container.keys():\n",
    "    graphs = merged_graph_container.graphs_at(key)\n",
    "    for graph in graphs:\n",
    "        torch_data = graph.data.to_torch()\n",
    "        \n",
    "        # do embedding\n",
    "        data = Data(x = embedded_data(torch_data.x), \n",
    "                edge_index = torch_data.edge_index,\n",
    "                y = torch_data.y,\n",
    "                edge_attr = torch_data.edge_attr,\n",
    "                pos = torch_data.pos)\n",
    "        data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3c9b3-f802-4981-9f88-abd2ac52234e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data_list[0].x)\n",
    "print(data_list[0].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e43a06-11c7-40b5-9fbd-5d8cb2179b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset\n",
    "import torch\n",
    "\n",
    "class PathLightDataset(InMemoryDataset):\n",
    "    def __init__(self, root, data_list=None, transform=None):\n",
    "        self.data_list = data_list\n",
    "        super().__init__(root, transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        torch.save(self.collate(self.data_list), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03b59625-ecb3-4588-a73b-c7a9879bed7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pl_dataset \u001b[38;5;241m=\u001b[39m PathLightDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/datasets/cornell\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mdata_list\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_list' is not defined"
     ]
    }
   ],
   "source": [
    "pl_dataset = PathLightDataset('data/datasets/cornell', data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4365032e-88cc-4e5b-a848-8dcb7928ee14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "# transform applied only when loaded\n",
    "dataset = PathLightDataset(root='data/datasets/cornell')\n",
    "\n",
    "split_index = int(len(dataset) * 0.8)\n",
    "train_dataset = dataset[:split_index]\n",
    "test_dataset = dataset[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90fc7e13-d388-4db8-a1e2-9142b40a53ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_scaler = MinMaxScaler(feature_range=(-1, 1)).fit(train_dataset.data.x)\n",
    "y_scaler = MinMaxScaler(feature_range=(-1, 1)).fit(train_dataset.data.y)\n",
    "\n",
    "#x_mean = train_dataset.data.x.mean(dim=0, keepdim=True)\n",
    "#x_std = train_dataset.data.x.std(dim=0, keepdim=True)\n",
    "#print(x_mean, x_std)\n",
    "\n",
    "#y_mean = train_dataset.data.y.mean(dim=0, keepdim=True)\n",
    "#y_std = train_dataset.data.y.std(dim=0, keepdim=True)\n",
    "#print(y_mean, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55c86e4f-8479-4fd4-ad51-ff97cc76522d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0627, 0.0411, 0.0111]])\n",
      "[[-0.99259065 -0.99311359 -0.99443767]]\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[1].y)\n",
    "print(y_scaler.transform(train_dataset[1].y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df960614-e60f-44bd-8264-8877781f7000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba56933a-5228-4131-b851-70b197956768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4313,  1.2040,  4.6265],\n",
      "        [ 0.6721,  1.2583, -1.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n",
      "tensor([6.0071,    inf])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0].pos)\n",
    "print(train_dataset[0].edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0e1dad01-c96e-4492-a174-4ecc11e9ea86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GraphConv(78, 256)\n",
      "  (conv2): GraphConv(256, 256)\n",
      "  (conv3): GraphConv(256, 1024)\n",
      "  (lin1): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (lin2): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n",
      "Number of params: 960003\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear, Conv2d\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GraphConv \n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, L=6):\n",
    "        \n",
    "        super(GCN, self).__init__()\n",
    "        self._n_features = dataset.num_node_features\n",
    "        self.conv1 = GraphConv(self._n_features * (L * 2) + self._n_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels * 4)\n",
    "        self.lin1 = Linear(hidden_channels * 4, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 3)\n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x_node = self.conv1(x, edge_index)\n",
    "        x_node = x_node.relu()\n",
    "        x_node = self.conv2(x_node, edge_index)\n",
    "        x_node = x_node.relu()\n",
    "        x_node = self.conv3(x_node, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        h_node = global_mean_pool(x_node, batch)  # [batch_size, hidden_channels]\n",
    "        \n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(h_node, p=0.5, training=self.training)\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=256)\n",
    "print(model)\n",
    "print(f'Number of params: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4cda789f-0a53-443c-a03f-20be27ee8c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (432x18 and 36x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m error \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader), r2_error \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(loader)  \u001b[38;5;66;03m# Derive ratio of correct predictions.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     train_loss, train_r2 \u001b[38;5;241m=\u001b[39m test(train_loader)\n\u001b[1;32m     49\u001b[0m     test_loss, test_r2 \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
      "Cell \u001b[0;32mIn[67], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch_id)\u001b[0m\n\u001b[1;32m     14\u001b[0m x_data \u001b[38;5;241m=\u001b[39m embedded_data(torch\u001b[38;5;241m.\u001b[39mtensor(x_scaler\u001b[38;5;241m.\u001b[39mtransform(data\u001b[38;5;241m.\u001b[39mx), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat))\n\u001b[1;32m     15\u001b[0m y_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_scaler\u001b[38;5;241m.\u001b[39mtransform(data\u001b[38;5;241m.\u001b[39my), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform a single forward pass.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, y_data)  \u001b[38;5;66;03m# Compute the loss.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m r2_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r2(out\u001b[38;5;241m.\u001b[39mflatten(), y_data\u001b[38;5;241m.\u001b[39mflatten())\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[65], line 19\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, edge_attr, edge_index, batch)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_attr, edge_index, batch):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# 1. Obtain node embeddings \u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     x_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     x_node \u001b[38;5;241m=\u001b[39m x_node\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m     21\u001b[0m     x_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x_node, edge_index)\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/torch_geometric/nn/conv/graph_conv.py:81\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, x, edge_index, edge_weight, size)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, edge_weight\u001b[38;5;241m=\u001b[39medge_weight,\n\u001b[1;32m     80\u001b[0m                      size\u001b[38;5;241m=\u001b[39msize)\n\u001b[0;32m---> 81\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_rel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/mitsuba-venv/lib/python3.9/site-packages/torch_geometric/nn/dense/linear.py:136\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        x (Tensor): The features.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (432x18 and 36x256)"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.HuberLoss()\n",
    "from torchmetrics import R2Score\n",
    "r2 = R2Score()\n",
    "\n",
    "def train(epoch_id):\n",
    "    model.train()\n",
    "\n",
    "    error = 0\n",
    "    r2_error = 0\n",
    "    for b_i, data in enumerate(train_loader):  # Iterate in batches over the training dataset.\n",
    "        \n",
    "        # normalize data\n",
    "        x_data = embedded_data(torch.tensor(x_scaler.transform(data.x), dtype=torch.float))\n",
    "        y_data = torch.tensor(y_scaler.transform(data.y), dtype=torch.float)\n",
    "        \n",
    "        out = model(x_data, data.edge_attr, data.edge_index, batch=data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, y_data)  # Compute the loss.\n",
    "        r2_error += r2(out.flatten(), y_data.flatten())\n",
    "        error += loss.item()\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        \n",
    "        print(f'Epoch n°{epoch_id} progress: {(b_i + 1) / len(train_loader) * 100.:.2f}%' \\\n",
    "            f' (Loss: {error / (b_i + 1):.5f}, R²: {r2_error / (b_i + 1):.5f})', end='\\r')\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    error = 0\n",
    "    r2_error = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        \n",
    "        # normalize data\n",
    "        x_data = embedded_data(torch.tensor(x_scaler.transform(data.x), dtype=torch.float))\n",
    "        y_data = torch.tensor(y_scaler.transform(data.y), dtype=torch.float)\n",
    "        \n",
    "        out = model(x_data, data.edge_attr, data.edge_index, batch=data.batch)\n",
    "        loss = criterion(out, y_data)\n",
    "        error += loss.item()  \n",
    "        r2_error += r2(out.flatten(), y_data.flatten())\n",
    "    return error / len(loader), r2_error / len(loader)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    train(epoch)\n",
    "    train_loss, train_r2 = test(train_loader)\n",
    "    test_loss, test_r2 = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train (Loss: {train_loss:.5f}, R²: {train_r2:.5f}), '\\\n",
    "        f'Test (Loss: {test_loss:.5f}, R²: {test_r2:.5f})', end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e15ac9-d821-4da2-bb1e-0dc34243fb14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_folder = 'data/models/model1'\n",
    "os.makedirs('data/models/model1', exist_ok=True)\n",
    "torch.save(model.state_dict(), f'{model_folder}/model.pt')\n",
    "torch.save(optimizer.state_dict(), f'{model_folder}/optimizer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424294b-2f9b-4335-b838-0d05d9e8344b",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8079e-5902-47b6-afeb-70f8320bc9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_file = 'scenes/cornell-box/scene.xml'\n",
    "output_folder = 'data/model1'\n",
    "\n",
    "scene = mi.load_file(scene_file)\n",
    "\n",
    "# get the reference image\n",
    "ref_integrator = mi.load_dict({'type': 'path', 'max_depth': max_depth})\n",
    "ref_image = mi.render(scene, integrator=ref_integrator, spp = 1000)\n",
    "\n",
    "# prepare path gnn data\n",
    "gnn_integrator = mi.load_dict({'type': 'pathgnn', 'max_depth': max_depth})\n",
    "params = mi.traverse(scene)\n",
    "gnn_log_filename = f'{output_folder}/gnn_file_predict.path'\n",
    "params['logfile'] = gnn_log_filename\n",
    "params.update();\n",
    "\n",
    "mi.render(scene, integrator=gnn_integrator, spp = 10)\n",
    "container = SimpleLightGraphContainer.fromfile(gnn_log_filename, scene_file, verbose=True)\n",
    "container.build_connections(n_graphs=10, n_nodes_per_graphs=5, n_neighbors=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f18e0-9f47-4c23-9776-2ea9772f1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "for key in container.keys():\n",
    "    graphs = container.graphs_at(key)\n",
    "    for graph in graphs:\n",
    "        torch_data = graph.data.to_torch()\n",
    "        \n",
    "        data = Data(x = torch_data.x, \n",
    "                edge_index = torch_data.edge_index,\n",
    "                y = torch_data.y,\n",
    "                edge_attr = torch_data.edge_attr,\n",
    "                pos = torch_data.pos)\n",
    "        \n",
    "        data.x = (data.x - x_mean) / x_std\n",
    "        data.y = (data.y - y_mean) / y_std\n",
    "        \n",
    "        # now predict and get value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitsuba-venv",
   "language": "python",
   "name": "mitsuba-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
